{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58b1dd8a",
   "metadata": {},
   "source": [
    "# Forest Cover Type Prediction - Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d5fda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iiitb/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.87683\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.89      0.88     12710\n",
      "           2       0.90      0.88      0.89     16998\n",
      "           3       0.85      0.90      0.87      2145\n",
      "           4       0.84      0.79      0.82       165\n",
      "           5       0.72      0.66      0.69       570\n",
      "           6       0.76      0.73      0.75      1042\n",
      "           7       0.92      0.89      0.90      1231\n",
      "\n",
      "    accuracy                           0.88     34861\n",
      "   macro avg       0.84      0.82      0.83     34861\n",
      "weighted avg       0.88      0.88      0.88     34861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('covtype.csv')\n",
    "\n",
    "df_sub, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=df['Cover_Type']\n",
    ")\n",
    "\n",
    "X = df_sub.drop(columns=['Cover_Type'])\n",
    "y = df_sub['Cover_Type']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128,),\n",
    "    activation='logistic',\n",
    "    solver='adam',\n",
    "    learning_rate='constant',\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06a74472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.89019\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.87      0.89     12710\n",
      "           2       0.89      0.92      0.91     16998\n",
      "           3       0.89      0.88      0.88      2145\n",
      "           4       0.86      0.78      0.82       165\n",
      "           5       0.80      0.63      0.71       570\n",
      "           6       0.78      0.80      0.79      1042\n",
      "           7       0.92      0.90      0.91      1231\n",
      "\n",
      "    accuracy                           0.89     34861\n",
      "   macro avg       0.86      0.82      0.84     34861\n",
      "weighted avg       0.89      0.89      0.89     34861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('covtype.csv')\n",
    "\n",
    "df_sub, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=df['Cover_Type']\n",
    ")\n",
    "\n",
    "X = df_sub.drop(columns=['Cover_Type'])\n",
    "y = df_sub['Cover_Type']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128,),\n",
    "    activation='logistic',\n",
    "    solver='adam',\n",
    "    learning_rate='constant',\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f4e742f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.89444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.89      0.89     12710\n",
      "           2       0.91      0.91      0.91     16998\n",
      "           3       0.90      0.87      0.89      2145\n",
      "           4       0.84      0.77      0.80       165\n",
      "           5       0.75      0.71      0.73       570\n",
      "           6       0.76      0.83      0.80      1042\n",
      "           7       0.94      0.92      0.93      1231\n",
      "\n",
      "    accuracy                           0.89     34861\n",
      "   macro avg       0.85      0.84      0.85     34861\n",
      "weighted avg       0.89      0.89      0.89     34861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('covtype.csv')\n",
    "\n",
    "df_sub, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=df['Cover_Type']\n",
    ")\n",
    "\n",
    "X = df_sub.drop(columns=['Cover_Type'])\n",
    "y = df_sub['Cover_Type']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128,),\n",
    "    activation='tanh',\n",
    "    solver='adam',\n",
    "    learning_rate='constant',\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebf70bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.87212\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.84      0.86     12710\n",
      "           2       0.87      0.92      0.89     16998\n",
      "           3       0.85      0.87      0.86      2145\n",
      "           4       0.85      0.78      0.81       165\n",
      "           5       0.75      0.59      0.66       570\n",
      "           6       0.76      0.69      0.72      1042\n",
      "           7       0.90      0.90      0.90      1231\n",
      "\n",
      "    accuracy                           0.87     34861\n",
      "   macro avg       0.84      0.80      0.82     34861\n",
      "weighted avg       0.87      0.87      0.87     34861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('covtype.csv')\n",
    "\n",
    "df_sub, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=df['Cover_Type']\n",
    ")\n",
    "\n",
    "X = df_sub.drop(columns=['Cover_Type'])\n",
    "y = df_sub['Cover_Type']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128,),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate='constant',\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0e45645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.89444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.89      0.89     12710\n",
      "           2       0.91      0.91      0.91     16998\n",
      "           3       0.90      0.87      0.89      2145\n",
      "           4       0.84      0.77      0.80       165\n",
      "           5       0.75      0.71      0.73       570\n",
      "           6       0.76      0.83      0.80      1042\n",
      "           7       0.94      0.92      0.93      1231\n",
      "\n",
      "    accuracy                           0.89     34861\n",
      "   macro avg       0.85      0.84      0.85     34861\n",
      "weighted avg       0.89      0.89      0.89     34861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('covtype.csv')\n",
    "\n",
    "df_sub, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=df['Cover_Type']\n",
    ")\n",
    "\n",
    "X = df_sub.drop(columns=['Cover_Type'])\n",
    "y = df_sub['Cover_Type']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128,),\n",
    "    activation='tanh',\n",
    "    solver='adam',\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50d33e2",
   "metadata": {},
   "source": [
    "adding more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c7e06f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.92028\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.93      0.92     12710\n",
      "           2       0.94      0.93      0.93     16998\n",
      "           3       0.90      0.90      0.90      2145\n",
      "           4       0.74      0.82      0.78       165\n",
      "           5       0.78      0.80      0.79       570\n",
      "           6       0.83      0.83      0.83      1042\n",
      "           7       0.92      0.92      0.92      1231\n",
      "\n",
      "    accuracy                           0.92     34861\n",
      "   macro avg       0.86      0.87      0.87     34861\n",
      "weighted avg       0.92      0.92      0.92     34861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('covtype.csv')\n",
    "\n",
    "df_sub, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=df['Cover_Type']\n",
    ")\n",
    "\n",
    "X = df_sub.drop(columns=['Cover_Type'])\n",
    "y = df_sub['Cover_Type']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128,64),\n",
    "    activation='tanh',\n",
    "    solver='adam',\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52bf868",
   "metadata": {},
   "source": [
    "adding an extra layer, adding regularization factor alpha and increasing max iterations for increasing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "716e536c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.92373\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.92      0.92     12710\n",
      "           2       0.93      0.94      0.94     16998\n",
      "           3       0.91      0.91      0.91      2145\n",
      "           4       0.82      0.76      0.79       165\n",
      "           5       0.77      0.80      0.78       570\n",
      "           6       0.82      0.86      0.84      1042\n",
      "           7       0.93      0.93      0.93      1231\n",
      "\n",
      "    accuracy                           0.92     34861\n",
      "   macro avg       0.87      0.87      0.87     34861\n",
      "weighted avg       0.92      0.92      0.92     34861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('covtype.csv')\n",
    "\n",
    "df_sub, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=df['Cover_Type']\n",
    ")\n",
    "\n",
    "X = df_sub.drop(columns=['Cover_Type'])\n",
    "y = df_sub['Cover_Type']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128,64,32),\n",
    "    activation='tanh',\n",
    "    solver='adam',\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    alpha=0.0001\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c44f95",
   "metadata": {},
   "source": [
    "increasing alpha, and layer weights, also increasing max iterations to improve accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5ccb57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.93032\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.93      0.93     12710\n",
      "           2       0.94      0.95      0.94     16998\n",
      "           3       0.92      0.90      0.91      2145\n",
      "           4       0.83      0.81      0.82       165\n",
      "           5       0.83      0.78      0.81       570\n",
      "           6       0.84      0.87      0.86      1042\n",
      "           7       0.95      0.93      0.94      1231\n",
      "\n",
      "    accuracy                           0.93     34861\n",
      "   macro avg       0.89      0.88      0.89     34861\n",
      "weighted avg       0.93      0.93      0.93     34861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('covtype.csv')\n",
    "\n",
    "df_sub, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=df['Cover_Type']\n",
    ")\n",
    "\n",
    "X = df_sub.drop(columns=['Cover_Type'])\n",
    "y = df_sub['Cover_Type']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(256,128,64),\n",
    "    activation='tanh',\n",
    "    solver='adam',\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=1500,\n",
    "    random_state=42,\n",
    "    alpha=0.0005\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1dd687",
   "metadata": {},
   "source": [
    "adding early stopping parameter to reduce the overfitting, increasing alpha more, adding one more layer , also increasing max iterations to improve accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8897e455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.92846\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.93      0.93     12710\n",
      "           2       0.94      0.94      0.94     16998\n",
      "           3       0.92      0.91      0.91      2145\n",
      "           4       0.86      0.81      0.83       165\n",
      "           5       0.78      0.80      0.79       570\n",
      "           6       0.84      0.86      0.85      1042\n",
      "           7       0.94      0.93      0.94      1231\n",
      "\n",
      "    accuracy                           0.93     34861\n",
      "   macro avg       0.89      0.88      0.88     34861\n",
      "weighted avg       0.93      0.93      0.93     34861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('covtype.csv')\n",
    "\n",
    "df_sub, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=df['Cover_Type']\n",
    ")\n",
    "\n",
    "X = df_sub.drop(columns=['Cover_Type'])\n",
    "y = df_sub['Cover_Type']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(256,128,128,64),\n",
    "    activation='tanh',\n",
    "    solver='adam',\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=2000,\n",
    "    random_state=42,\n",
    "    alpha=0.001,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ed22369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.92849\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.93      0.93     12710\n",
      "           2       0.94      0.94      0.94     16998\n",
      "           3       0.91      0.92      0.92      2145\n",
      "           4       0.91      0.75      0.82       165\n",
      "           5       0.84      0.75      0.79       570\n",
      "           6       0.86      0.84      0.85      1042\n",
      "           7       0.95      0.91      0.93      1231\n",
      "\n",
      "    accuracy                           0.93     34861\n",
      "   macro avg       0.91      0.86      0.88     34861\n",
      "weighted avg       0.93      0.93      0.93     34861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('covtype.csv')\n",
    "\n",
    "df_sub, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=df['Cover_Type']\n",
    ")\n",
    "\n",
    "X = df_sub.drop(columns=['Cover_Type'])\n",
    "y = df_sub['Cover_Type']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(256,128,128,64),\n",
    "    activation='tanh',\n",
    "    solver='adam',\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=2000,\n",
    "    random_state=42,\n",
    "    alpha=0.0005,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7330425d",
   "metadata": {},
   "source": [
    "no significant improvement, so i'm tried training the model on 40% of the whole data to see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5be507ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.93759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.93      0.94     16947\n",
      "           2       0.94      0.96      0.95     22664\n",
      "           3       0.93      0.91      0.92      2860\n",
      "           4       0.83      0.80      0.81       220\n",
      "           5       0.84      0.82      0.83       759\n",
      "           6       0.85      0.88      0.87      1390\n",
      "           7       0.92      0.96      0.94      1641\n",
      "\n",
      "    accuracy                           0.94     46481\n",
      "   macro avg       0.89      0.89      0.89     46481\n",
      "weighted avg       0.94      0.94      0.94     46481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('covtype.csv')\n",
    "\n",
    "df_sub, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=0.40,\n",
    "    random_state=42,\n",
    "    stratify=df['Cover_Type']\n",
    ")\n",
    "\n",
    "X = df_sub.drop(columns=['Cover_Type'])\n",
    "y = df_sub['Cover_Type']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(256,128,64),\n",
    "    activation='tanh',\n",
    "    solver='adam',\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=1500,\n",
    "    random_state=42,\n",
    "    alpha=0.0005\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bb42b8",
   "metadata": {},
   "source": [
    "since increasing the sub sample lead to increase in accuracy, i'm increasing the sub sample size more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "776749e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.94322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.95      0.94     21184\n",
      "           2       0.95      0.95      0.95     28330\n",
      "           3       0.94      0.94      0.94      3576\n",
      "           4       0.84      0.83      0.84       275\n",
      "           5       0.86      0.82      0.84       949\n",
      "           6       0.88      0.88      0.88      1737\n",
      "           7       0.95      0.93      0.94      2051\n",
      "\n",
      "    accuracy                           0.94     58102\n",
      "   macro avg       0.91      0.90      0.90     58102\n",
      "weighted avg       0.94      0.94      0.94     58102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('covtype.csv')\n",
    "\n",
    "df_sub, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=0.50,\n",
    "    random_state=42,\n",
    "    stratify=df['Cover_Type']\n",
    ")\n",
    "\n",
    "X = df_sub.drop(columns=['Cover_Type'])\n",
    "y = df_sub['Cover_Type']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(256,128,64),\n",
    "    activation='tanh',\n",
    "    solver='adam',\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=1500,\n",
    "    random_state=42,\n",
    "    alpha=0.0005\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a3700f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5227bda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.95195\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.95      0.95     33894\n",
      "           2       0.96      0.96      0.96     45328\n",
      "           3       0.96      0.93      0.94      5721\n",
      "           4       0.79      0.86      0.82       439\n",
      "           5       0.87      0.85      0.86      1519\n",
      "           6       0.89      0.92      0.91      2779\n",
      "           7       0.96      0.96      0.96      3282\n",
      "\n",
      "    accuracy                           0.95     92962\n",
      "   macro avg       0.91      0.92      0.91     92962\n",
      "weighted avg       0.95      0.95      0.95     92962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('covtype.csv')\n",
    "\n",
    "df_sub, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=0.80,\n",
    "    random_state=42,\n",
    "    stratify=df['Cover_Type']\n",
    ")\n",
    "\n",
    "X = df_sub.drop(columns=['Cover_Type'])\n",
    "y = df_sub['Cover_Type']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(256,128,64),\n",
    "    activation='tanh',\n",
    "    solver='adam',\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=1500,\n",
    "    random_state=42,\n",
    "    alpha=0.0005\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185a91f6",
   "metadata": {},
   "source": [
    "final accuracy check on whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ebd2a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.95418\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.95      0.95     42368\n",
      "           2       0.96      0.97      0.96     56661\n",
      "           3       0.94      0.96      0.95      7151\n",
      "           4       0.87      0.87      0.87       549\n",
      "           5       0.90      0.86      0.88      1899\n",
      "           6       0.93      0.88      0.91      3473\n",
      "           7       0.95      0.96      0.96      4102\n",
      "\n",
      "    accuracy                           0.95    116203\n",
      "   macro avg       0.93      0.92      0.92    116203\n",
      "weighted avg       0.95      0.95      0.95    116203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('covtype.csv')\n",
    "\n",
    "X = df.drop(columns=['Cover_Type'])\n",
    "y = df['Cover_Type']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(256,128,64),\n",
    "    activation='tanh',\n",
    "    solver='adam',\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=1500,\n",
    "    random_state=42,\n",
    "    alpha=0.0005\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d011f22a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44fa800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /home/iiitb/anaconda3/lib/python3.13/site-packages (4.6.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/iiitb/anaconda3/lib/python3.13/site-packages (from optuna) (1.16.2)\n",
      "Requirement already satisfied: colorlog in /home/iiitb/anaconda3/lib/python3.13/site-packages (from optuna) (6.10.1)\n",
      "Requirement already satisfied: numpy in /home/iiitb/anaconda3/lib/python3.13/site-packages (from optuna) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/iiitb/anaconda3/lib/python3.13/site-packages (from optuna) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /home/iiitb/anaconda3/lib/python3.13/site-packages (from optuna) (2.0.39)\n",
      "Requirement already satisfied: tqdm in /home/iiitb/anaconda3/lib/python3.13/site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /home/iiitb/anaconda3/lib/python3.13/site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in /home/iiitb/anaconda3/lib/python3.13/site-packages (from alembic>=1.5.0->optuna) (1.2.3)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /home/iiitb/anaconda3/lib/python3.13/site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/iiitb/anaconda3/lib/python3.13/site-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/iiitb/anaconda3/lib/python3.13/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optuna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4260615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-11 18:31:26,597] A new study created in memory with name: no-name-4e776fd6-5e6c-4c4e-a437-5c6dd9608e6a\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4764874e574cfdb75fd57aed18111e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-11 18:54:22,870] Trial 0 finished with value: 0.9275858705816882 and parameters: {'layer1': 256, 'layer2': 196, 'layer3': 84, 'alpha': 0.0009340308327072935, 'max_iter': 909}. Best is trial 0 with value: 0.9275858705816882.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.read_csv(\"covtype.csv\")\n",
    "\n",
    "df_sub, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=df[\"Cover_Type\"]\n",
    ")\n",
    "\n",
    "X = df_sub.drop(columns=[\"Cover_Type\"])\n",
    "y = df_sub[\"Cover_Type\"]\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    layer1 = trial.suggest_int(\"layer1\", 200, 350)\n",
    "    layer2 = trial.suggest_int(\"layer2\", 100, 200)\n",
    "    layer3 = trial.suggest_int(\"layer3\", 40, 100)\n",
    "\n",
    "    alpha = trial.suggest_float(\"alpha\", 3e-4, 2e-3, log=True)\n",
    "    max_iter = trial.suggest_int(\"max_iter\", 800, 1500)\n",
    "\n",
    "    model = MLPClassifier(\n",
    "        hidden_layer_sizes=(layer1, layer2, layer3),\n",
    "        activation=\"tanh\",\n",
    "        solver=\"adam\",\n",
    "        learning_rate=\"adaptive\",\n",
    "        alpha=alpha,\n",
    "        max_iter=max_iter,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    score = cross_val_score(\n",
    "        model,\n",
    "        X_scaled,\n",
    "        y,\n",
    "        cv=3,\n",
    "        scoring=\"accuracy\",\n",
    "        n_jobs=1\n",
    "    ).mean()\n",
    "\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=TPESampler(seed=42)\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(\"Best Params:\", study.best_trial.params)\n",
    "print(\"Best CV Accuracy:\", study.best_value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
