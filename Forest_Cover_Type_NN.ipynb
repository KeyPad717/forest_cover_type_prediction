{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58b1dd8a",
   "metadata": {},
   "source": [
    "# Forest Cover Type Prediction - Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d5fda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iiitb/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.87683\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.89      0.88     12710\n",
      "           2       0.90      0.88      0.89     16998\n",
      "           3       0.85      0.90      0.87      2145\n",
      "           4       0.84      0.79      0.82       165\n",
      "           5       0.72      0.66      0.69       570\n",
      "           6       0.76      0.73      0.75      1042\n",
      "           7       0.92      0.89      0.90      1231\n",
      "\n",
      "    accuracy                           0.88     34861\n",
      "   macro avg       0.84      0.82      0.83     34861\n",
      "weighted avg       0.88      0.88      0.88     34861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('covtype.csv')\n",
    "\n",
    "df_sub, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=df['Cover_Type']\n",
    ")\n",
    "\n",
    "X = df_sub.drop(columns=['Cover_Type'])\n",
    "y = df_sub['Cover_Type']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128,),\n",
    "    activation='logistic',\n",
    "    solver='adam',\n",
    "    learning_rate='constant',\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06a74472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.89019\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.87      0.89     12710\n",
      "           2       0.89      0.92      0.91     16998\n",
      "           3       0.89      0.88      0.88      2145\n",
      "           4       0.86      0.78      0.82       165\n",
      "           5       0.80      0.63      0.71       570\n",
      "           6       0.78      0.80      0.79      1042\n",
      "           7       0.92      0.90      0.91      1231\n",
      "\n",
      "    accuracy                           0.89     34861\n",
      "   macro avg       0.86      0.82      0.84     34861\n",
      "weighted avg       0.89      0.89      0.89     34861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('covtype.csv')\n",
    "\n",
    "df_sub, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=df['Cover_Type']\n",
    ")\n",
    "\n",
    "X = df_sub.drop(columns=['Cover_Type'])\n",
    "y = df_sub['Cover_Type']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128,),\n",
    "    activation='logistic',\n",
    "    solver='adam',\n",
    "    learning_rate='constant',\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f4e742f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.89444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.89      0.89     12710\n",
      "           2       0.91      0.91      0.91     16998\n",
      "           3       0.90      0.87      0.89      2145\n",
      "           4       0.84      0.77      0.80       165\n",
      "           5       0.75      0.71      0.73       570\n",
      "           6       0.76      0.83      0.80      1042\n",
      "           7       0.94      0.92      0.93      1231\n",
      "\n",
      "    accuracy                           0.89     34861\n",
      "   macro avg       0.85      0.84      0.85     34861\n",
      "weighted avg       0.89      0.89      0.89     34861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('covtype.csv')\n",
    "\n",
    "df_sub, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=df['Cover_Type']\n",
    ")\n",
    "\n",
    "X = df_sub.drop(columns=['Cover_Type'])\n",
    "y = df_sub['Cover_Type']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128,),\n",
    "    activation='tanh',\n",
    "    solver='adam',\n",
    "    learning_rate='constant',\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebf70bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.87212\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.84      0.86     12710\n",
      "           2       0.87      0.92      0.89     16998\n",
      "           3       0.85      0.87      0.86      2145\n",
      "           4       0.85      0.78      0.81       165\n",
      "           5       0.75      0.59      0.66       570\n",
      "           6       0.76      0.69      0.72      1042\n",
      "           7       0.90      0.90      0.90      1231\n",
      "\n",
      "    accuracy                           0.87     34861\n",
      "   macro avg       0.84      0.80      0.82     34861\n",
      "weighted avg       0.87      0.87      0.87     34861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('covtype.csv')\n",
    "\n",
    "df_sub, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=df['Cover_Type']\n",
    ")\n",
    "\n",
    "X = df_sub.drop(columns=['Cover_Type'])\n",
    "y = df_sub['Cover_Type']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128,),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate='constant',\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0e45645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.89444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.89      0.89     12710\n",
      "           2       0.91      0.91      0.91     16998\n",
      "           3       0.90      0.87      0.89      2145\n",
      "           4       0.84      0.77      0.80       165\n",
      "           5       0.75      0.71      0.73       570\n",
      "           6       0.76      0.83      0.80      1042\n",
      "           7       0.94      0.92      0.93      1231\n",
      "\n",
      "    accuracy                           0.89     34861\n",
      "   macro avg       0.85      0.84      0.85     34861\n",
      "weighted avg       0.89      0.89      0.89     34861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('covtype.csv')\n",
    "\n",
    "df_sub, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=df['Cover_Type']\n",
    ")\n",
    "\n",
    "X = df_sub.drop(columns=['Cover_Type'])\n",
    "y = df_sub['Cover_Type']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128,),\n",
    "    activation='tanh',\n",
    "    solver='adam',\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50d33e2",
   "metadata": {},
   "source": [
    "adding more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c7e06f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.92028\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.93      0.92     12710\n",
      "           2       0.94      0.93      0.93     16998\n",
      "           3       0.90      0.90      0.90      2145\n",
      "           4       0.74      0.82      0.78       165\n",
      "           5       0.78      0.80      0.79       570\n",
      "           6       0.83      0.83      0.83      1042\n",
      "           7       0.92      0.92      0.92      1231\n",
      "\n",
      "    accuracy                           0.92     34861\n",
      "   macro avg       0.86      0.87      0.87     34861\n",
      "weighted avg       0.92      0.92      0.92     34861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('covtype.csv')\n",
    "\n",
    "df_sub, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=df['Cover_Type']\n",
    ")\n",
    "\n",
    "X = df_sub.drop(columns=['Cover_Type'])\n",
    "y = df_sub['Cover_Type']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128,64),\n",
    "    activation='tanh',\n",
    "    solver='adam',\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52bf868",
   "metadata": {},
   "source": [
    "adding an extra layer, adding regularization factor alpha and increasing max iterations for increasing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "716e536c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.92373\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.92      0.92     12710\n",
      "           2       0.93      0.94      0.94     16998\n",
      "           3       0.91      0.91      0.91      2145\n",
      "           4       0.82      0.76      0.79       165\n",
      "           5       0.77      0.80      0.78       570\n",
      "           6       0.82      0.86      0.84      1042\n",
      "           7       0.93      0.93      0.93      1231\n",
      "\n",
      "    accuracy                           0.92     34861\n",
      "   macro avg       0.87      0.87      0.87     34861\n",
      "weighted avg       0.92      0.92      0.92     34861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('covtype.csv')\n",
    "\n",
    "df_sub, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=df['Cover_Type']\n",
    ")\n",
    "\n",
    "X = df_sub.drop(columns=['Cover_Type'])\n",
    "y = df_sub['Cover_Type']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128,64,32),\n",
    "    activation='tanh',\n",
    "    solver='adam',\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    alpha=0.0001\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c44f95",
   "metadata": {},
   "source": [
    "increasing alpha, and layer weights, also increasing max iterations to improve accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5ccb57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.93032\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.93      0.93     12710\n",
      "           2       0.94      0.95      0.94     16998\n",
      "           3       0.92      0.90      0.91      2145\n",
      "           4       0.83      0.81      0.82       165\n",
      "           5       0.83      0.78      0.81       570\n",
      "           6       0.84      0.87      0.86      1042\n",
      "           7       0.95      0.93      0.94      1231\n",
      "\n",
      "    accuracy                           0.93     34861\n",
      "   macro avg       0.89      0.88      0.89     34861\n",
      "weighted avg       0.93      0.93      0.93     34861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('covtype.csv')\n",
    "\n",
    "df_sub, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=df['Cover_Type']\n",
    ")\n",
    "\n",
    "X = df_sub.drop(columns=['Cover_Type'])\n",
    "y = df_sub['Cover_Type']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(256,128,64),\n",
    "    activation='tanh',\n",
    "    solver='adam',\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=1500,\n",
    "    random_state=42,\n",
    "    alpha=0.0005\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1dd687",
   "metadata": {},
   "source": [
    "adding early stopping parameter to reduce the overfitting, increasing alpha more, adding one more layer , also increasing max iterations to improve accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8897e455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.92846\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.93      0.93     12710\n",
      "           2       0.94      0.94      0.94     16998\n",
      "           3       0.92      0.91      0.91      2145\n",
      "           4       0.86      0.81      0.83       165\n",
      "           5       0.78      0.80      0.79       570\n",
      "           6       0.84      0.86      0.85      1042\n",
      "           7       0.94      0.93      0.94      1231\n",
      "\n",
      "    accuracy                           0.93     34861\n",
      "   macro avg       0.89      0.88      0.88     34861\n",
      "weighted avg       0.93      0.93      0.93     34861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('covtype.csv')\n",
    "\n",
    "df_sub, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=df['Cover_Type']\n",
    ")\n",
    "\n",
    "X = df_sub.drop(columns=['Cover_Type'])\n",
    "y = df_sub['Cover_Type']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(256,128,128,64),\n",
    "    activation='tanh',\n",
    "    solver='adam',\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=2000,\n",
    "    random_state=42,\n",
    "    alpha=0.001,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ed22369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.92849\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.93      0.93     12710\n",
      "           2       0.94      0.94      0.94     16998\n",
      "           3       0.91      0.92      0.92      2145\n",
      "           4       0.91      0.75      0.82       165\n",
      "           5       0.84      0.75      0.79       570\n",
      "           6       0.86      0.84      0.85      1042\n",
      "           7       0.95      0.91      0.93      1231\n",
      "\n",
      "    accuracy                           0.93     34861\n",
      "   macro avg       0.91      0.86      0.88     34861\n",
      "weighted avg       0.93      0.93      0.93     34861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('covtype.csv')\n",
    "\n",
    "df_sub, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=df['Cover_Type']\n",
    ")\n",
    "\n",
    "X = df_sub.drop(columns=['Cover_Type'])\n",
    "y = df_sub['Cover_Type']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(256,128,128,64),\n",
    "    activation='tanh',\n",
    "    solver='adam',\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=2000,\n",
    "    random_state=42,\n",
    "    alpha=0.0005,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7330425d",
   "metadata": {},
   "source": [
    "no significant improvement, so i'm tried training the model on 40% of the whole data to see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5be507ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.93759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.93      0.94     16947\n",
      "           2       0.94      0.96      0.95     22664\n",
      "           3       0.93      0.91      0.92      2860\n",
      "           4       0.83      0.80      0.81       220\n",
      "           5       0.84      0.82      0.83       759\n",
      "           6       0.85      0.88      0.87      1390\n",
      "           7       0.92      0.96      0.94      1641\n",
      "\n",
      "    accuracy                           0.94     46481\n",
      "   macro avg       0.89      0.89      0.89     46481\n",
      "weighted avg       0.94      0.94      0.94     46481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('covtype.csv')\n",
    "\n",
    "df_sub, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=0.40,\n",
    "    random_state=42,\n",
    "    stratify=df['Cover_Type']\n",
    ")\n",
    "\n",
    "X = df_sub.drop(columns=['Cover_Type'])\n",
    "y = df_sub['Cover_Type']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(256,128,64),\n",
    "    activation='tanh',\n",
    "    solver='adam',\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=1500,\n",
    "    random_state=42,\n",
    "    alpha=0.0005\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bb42b8",
   "metadata": {},
   "source": [
    "since increasing the sub sample lead to increase in accuracy, i'm increasing the sub sample size more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "776749e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.94322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.95      0.94     21184\n",
      "           2       0.95      0.95      0.95     28330\n",
      "           3       0.94      0.94      0.94      3576\n",
      "           4       0.84      0.83      0.84       275\n",
      "           5       0.86      0.82      0.84       949\n",
      "           6       0.88      0.88      0.88      1737\n",
      "           7       0.95      0.93      0.94      2051\n",
      "\n",
      "    accuracy                           0.94     58102\n",
      "   macro avg       0.91      0.90      0.90     58102\n",
      "weighted avg       0.94      0.94      0.94     58102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('covtype.csv')\n",
    "\n",
    "df_sub, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=0.50,\n",
    "    random_state=42,\n",
    "    stratify=df['Cover_Type']\n",
    ")\n",
    "\n",
    "X = df_sub.drop(columns=['Cover_Type'])\n",
    "y = df_sub['Cover_Type']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(256,128,64),\n",
    "    activation='tanh',\n",
    "    solver='adam',\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=1500,\n",
    "    random_state=42,\n",
    "    alpha=0.0005\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a3700f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5227bda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.95195\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.95      0.95     33894\n",
      "           2       0.96      0.96      0.96     45328\n",
      "           3       0.96      0.93      0.94      5721\n",
      "           4       0.79      0.86      0.82       439\n",
      "           5       0.87      0.85      0.86      1519\n",
      "           6       0.89      0.92      0.91      2779\n",
      "           7       0.96      0.96      0.96      3282\n",
      "\n",
      "    accuracy                           0.95     92962\n",
      "   macro avg       0.91      0.92      0.91     92962\n",
      "weighted avg       0.95      0.95      0.95     92962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('covtype.csv')\n",
    "\n",
    "df_sub, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=0.80,\n",
    "    random_state=42,\n",
    "    stratify=df['Cover_Type']\n",
    ")\n",
    "\n",
    "X = df_sub.drop(columns=['Cover_Type'])\n",
    "y = df_sub['Cover_Type']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(256,128,64),\n",
    "    activation='tanh',\n",
    "    solver='adam',\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=1500,\n",
    "    random_state=42,\n",
    "    alpha=0.0005\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
